{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep and Exploratory Analysis\n",
        "* To succecfully run this notebook you need a python3.7 kernel with requirements in ./docker-custom-image/requirements.txt"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook will help you to do:\n",
        "* Import raw data from Amazon Athena\n",
        "* Feature Engineering\n",
        "* Univariate Analysis\n",
        "* Bivariate Analysis\n",
        "* Save final dataset with the selected features to CSV to train the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Parameters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Name\n",
        "ModelName = 'titanic_propensity_survive'\n",
        "\n",
        "#Setting the model target variable name\n",
        "VarTarget = 'Survived'\n",
        "VarId = 'PassengerId'\n",
        "VarDate = 'ReferenceDate' \n",
        "\n",
        "#process outputs such as MOJO model, images and performance of tested models\n",
        "OutputPath = './output_model/'\n",
        "\n",
        "#If you have a huge dataset, I should consider use a small sample for first execution\n",
        "PctSampleSize = 1"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1669855913387
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -r requirements.txt"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import sys\n",
        "    sys.path.append('/anaconda/envs/azureml_py38/lib/python3.8/site-packages')    \n",
        "except:\n",
        "    pass"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1669469659432
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sweetviz as sv\n",
        "from io import StringIO\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469660825
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import raw data from CSV"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para mais detalhes sobre a base do Titanic, consulte seu [link](https://www.kaggle.com/competitions/titanic/data) no Kaggle"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataprep_df_full = pd.read_csv('./titanic/train.csv')\n",
        "dataprep_df_full"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469661206
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Na base do Titanic não tem a variável de Data de Referencia, mas vamos criar essa variável apenas para mostrar como o código funciona com uma base que tem Safra \n",
        "random.seed(1)\n",
        "for i in range(len(dataprep_df_full)):\n",
        "    dataprep_df_full.loc[i, (VarDate)] = random.choice(['1912-04','1912-05','1912-06', '1912-07'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469661584
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Work with a sample data if the PctSampleSize is less than 1\n",
        "if PctSampleSize == 1:\n",
        "    dataprep_df = dataprep_df_full.copy()\n",
        "else:\n",
        "    dataprep_df = dataprep_df_full.sample(frac=PctSampleSize, replace=False, random_state=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469661992
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Analyse the target variable"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataprep_df.groupby([VarTarget])[VarId].count().plot(kind='barh')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469662525
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Define the data time period for used to traing de model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataprep_target = dataprep_df[[VarDate, VarId, VarTarget]].groupby(VarDate).agg({VarId:'count', VarTarget:'sum'})\n",
        "dataprep_target['target_rate'] = dataprep_target[VarTarget] / dataprep_target[VarId]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469663046
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataprep_target[VarId].plot(secondary_y=False, kind='bar', rot=90, figsize=(15,5), linewidth=2, fontsize=12, grid=True, legend=1, title=(\"# Observations / % Good Rate\"))\n",
        "ax = dataprep_target.target_rate.plot(secondary_y=True, kind=\"line\", rot=90, figsize=(15,5), linewidth=2, fontsize=12, marker=\"D\", ms=8, grid=True, color='r', legend=1)\n",
        "for p in range(len(dataprep_target)):\n",
        "    ax.annotate(str('{0:.1%}'.format(int(dataprep_target.reset_index().iloc[p,3]*1000)/1000)), (dataprep_target.reset_index().index.values[p], dataprep_target.reset_index().iloc[p,3]*1))        "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469663625
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Separate the dataset into Traning and Test, ensuring the test dataset is an out of time sample"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "##Defined out of time validation (1912-07)\n",
        "dataprep_df['dataset'] = ['train' if x <= '1912-06' else 'test' for x in dataprep_df[VarDate]]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469664034
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataprep_target = dataprep_df[[VarDate, VarId, VarTarget, 'dataset']].groupby(by=[VarDate, 'dataset']).agg({VarId:'count', VarTarget:'sum'})\n",
        "dataprep_target['target_rate'] = dataprep_target[VarTarget] / dataprep_target[VarId]\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469664419
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataprep_target[VarId].plot(secondary_y=False, kind='bar', rot=90, figsize=(15,5), linewidth=2, fontsize=12, grid=True, legend=1, title=(\"# Observations / % Good Rate\"))\n",
        "ax = dataprep_target.target_rate.plot(secondary_y=True, kind=\"line\", rot=90, figsize=(15,5), linewidth=2, fontsize=12, marker=\"D\", ms=8, grid=True, color='r', legend=1)\n",
        "for p in range(len(dataprep_target)):\n",
        "    ax.annotate(str('{0:.1%}'.format(int(dataprep_target.reset_index().iloc[p,4]*1000)/1000)), (dataprep_target.reset_index().index.values[p], dataprep_target.reset_index().iloc[p,4]*1))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469664873
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Feature Engineering"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.046107,
          "end_time": "2021-04-22T18:42:43.076267",
          "exception": false,
          "start_time": "2021-04-22T18:42:43.030160",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#criar o prefix para a variavel cabine (A, B, C, D, ou E)\n",
        "dataprep_df['cabine_prefix'] = dataprep_df['Cabin'].str[0:1]\n",
        "dataprep_df = dataprep_df.fillna(value={'cabine_prefix': 'missing'})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469665303
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tiket\n",
        "import re\n",
        "for i in range(len(dataprep_df)):\n",
        "    t=dataprep_df.loc[i:i,'Ticket'].values\n",
        "    t2=re.sub(\"[^0-9]\", \"\", str(t))\n",
        "    t3=re.sub('[^A-Za-z]+', '', str(t))\n",
        "    if t2 != \"\":\n",
        "        dataprep_df.loc[i:i,'Ticket_int']=int(t2)\n",
        "    if t3 != \"\":\n",
        "        if t3 == 'SC':\n",
        "            t3 = 'SCAHBasle'\n",
        "        if t3 == 'SOP':\n",
        "            t3 = 'SOPP'\n",
        "        if t3 == 'C':\n",
        "            t3 = 'CA'\n",
        "        if t3 == 'FC':\n",
        "            t3 = 'FCC'\n",
        "        if t3 == 'PP':\n",
        "            t3 = 'PPP'\n",
        "        if t3 == 'SCOW':\n",
        "            t3 = 'Fa'\n",
        "        if t3 in ('AS', 'CASOTON', 'Fa', 'SCA','SOPP','SOTONO','SP'):\n",
        "            t3='LOW'\n",
        "    dataprep_df.loc[i:i,'Ticket_str']=str(t3)\n",
        "\n",
        "dataprep_df['Ticket_int'] = dataprep_df['Ticket_int'].fillna(0)\n",
        "dataprep_df = dataprep_df.fillna(value={'Ticket_str': 'missing'})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469665768
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Name: Criar uma categoria com o titulo do nome\n",
        "for i in range(len(dataprep_df)):\n",
        "    t1 = str(dataprep_df.loc[i:i,'Name'].values)\n",
        "    t2 = t1[0:t1.find('.')].split()[-1]\n",
        "    if t2 in ('Rev', 'Capt', 'Don', 'Jonkheer'):\n",
        "        t2='LOW'\n",
        "    if t2 in ('Lady', 'Mme'):\n",
        "        t2='Miss'\n",
        "    dataprep_df.loc[i:i,'NameTitle']=str(t2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469666155
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Treatment of Numeric Missing Data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the \"Missing\" category for missing values in string vaviables\n",
        "dataprep_df = dataprep_df.apply(lambda x: x.fillna(np.nan) if x.dtype.kind in 'biufc' else x.fillna('Missing'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469666561
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tratamento da idade\n",
        "dataprep_df['Age_Mean'] = dataprep_df['Age'].fillna(dataprep_df['Age'].mean())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469666955
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Univariate Analysis"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.047474,
          "end_time": "2021-04-22T18:42:46.866993",
          "exception": false,
          "start_time": "2021-04-22T18:42:46.819519",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 EDA with Sweetviz"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.047844,
          "end_time": "2021-04-22T18:42:46.962463",
          "exception": false,
          "start_time": "2021-04-22T18:42:46.914619",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### For more details on the pandas profiling library see [here](https://github.com/fbdesignpro/sweetviz)\n"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.047558,
          "end_time": "2021-04-22T18:42:47.057497",
          "exception": false,
          "start_time": "2021-04-22T18:42:47.009939",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analysis = sv.analyze(dataprep_df)\n",
        "analysis.show_notebook()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1669469670585
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Classify the types of variables\n",
        "#### list all columns to select the ones to be used"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.801446,
          "end_time": "2021-04-22T18:44:59.497584",
          "exception": false,
          "start_time": "2021-04-22T18:44:57.696138",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dataprep_df.columns:\n",
        "    print(i + \": \" + analysis.get_type(i).name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469670947
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From the variables listed above you can select which  one will be tested in the model and confirm if the correct type is numeric(NUM) or categorical (CAT). Paste the correct information below:"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.833422,
          "end_time": "2021-04-22T18:45:07.589978",
          "exception": false,
          "start_time": "2021-04-22T18:45:05.756556",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#It is necessary to define the types of variables (cageroric and numeric) to ensure that the type of data used in the modeling will be the most suitable.\n",
        "#For example, categorical variables need to be defined as a string because this prevents it from being treated as a numeric variable in H20 modeling\n",
        "#Another example is that the string variables will have a missing treatment by placing the missing category for all values found as 'null'\n",
        "CAT = ['Pclass'\n",
        ",'Embarked'\n",
        ",'cabine_prefix'\n",
        ",'Ticket_str'\n",
        ",'NameTitle']\n",
        "\n",
        "#float\n",
        "NUM = ['Fare'\n",
        ",'SibSp'\n",
        ",'Parch'\n",
        ",'Age_Mean'\n",
        ",'Ticket_int']\n",
        "selected_features = CAT + NUM"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469671181
        },
        "papermill": {
          "duration": 1.816755,
          "end_time": "2021-04-22T18:45:11.215660",
          "exception": false,
          "start_time": "2021-04-22T18:45:09.398905",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Numeric features must be float type\n",
        "for col_name in NUM:\n",
        "    dataprep_df[col_name] = dataprep_df[col_name].astype(float)\n",
        "\n",
        "#Categorical features must be string\n",
        "for col_name in CAT:\n",
        "    dataprep_df[col_name] = dataprep_df[col_name].astype(str)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469671505
        },
        "papermill": {
          "duration": 1.860101,
          "end_time": "2021-04-22T18:45:15.821982",
          "exception": false,
          "start_time": "2021-04-22T18:45:13.961881",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Outlier Analysys with Box plot and Violin Plot"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_comparison(x, title):\n",
        "    fig, ax = plt.subplots(3, 1, sharex=True, constrained_layout=True, figsize=(15,5))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    sns.distplot(x.rename(\"\"), ax=ax[0])\n",
        "    ax[0].set_title('Histogram + KDE')\n",
        "    sns.boxplot(x.rename(\"\"), ax=ax[1])\n",
        "    ax[1].set_title('Boxplot')\n",
        "    sns.violinplot(x.rename(\"\"), ax=ax[2])\n",
        "    ax[2].set_title('Violin plot')\n",
        "    plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469671855
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Distribution analysis of numerical variables\n",
        "for i in NUM:\n",
        "    print(i)\n",
        "    plot_comparison(dataprep_df[i], i)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469672737
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Outliers Removing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "var = 'Fare'\n",
        "\n",
        "q_low = dataprep_df[var].quantile(0)\n",
        "q_hi  = dataprep_df[var].quantile(0.997)\n",
        "print('Low: ' + str(q_low))\n",
        "print('High: ' + str(q_hi))\n",
        "print('Reduction: ' \n",
        "      + \"{0:.2%}\".format(len(dataprep_df[(dataprep_df[var] <= q_hi) & (dataprep_df[var] >= q_low)])/len(dataprep_df)-1) \n",
        "      + \" | \" \n",
        "      + str(len(dataprep_df)-len(dataprep_df[(dataprep_df[var] <= q_hi) & (dataprep_df[var] >= q_low)])))\n",
        "\n",
        "def plot_comparison(x, title, low, high):\n",
        "    fig, ax = plt.subplots(3, 1, sharex=True, constrained_layout=True, figsize=(15,5))\n",
        "    fig.suptitle(title, fontsize=16)\n",
        "    sns.distplot(x.rename(\"\"), ax=ax[0])\n",
        "    ax[0].set_title('Histogram + KDE')\n",
        "    sns.boxplot(x.rename(\"\"), ax=ax[1])\n",
        "    ax[1].set_title('Boxplot')\n",
        "    sns.violinplot(x.rename(\"\"), ax=ax[2])\n",
        "    ax[2].set_title('Violin plot')\n",
        "    # only one line may be specified; full height\n",
        "    ax[1].axvline(x = low, color = 'red')\n",
        "    ax[1].axvline(x = high, color = 'red')\n",
        "    plt.show()\n",
        "    \n",
        "plot_comparison(dataprep_df[var], var, q_low, q_hi)\n",
        "\n",
        "dataprep_df = dataprep_df[(dataprep_df[var] <= q_hi) & (dataprep_df[var] >= q_low)]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469673114
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Bivariate Analysis"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.8015,
          "end_time": "2021-04-22T18:45:19.445742",
          "exception": false,
          "start_time": "2021-04-22T18:45:17.644242",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Calculation of the Information Value for all variables defined as selected features"
      ],
      "metadata": {
        "papermill": {
          "duration": 2.149903,
          "end_time": "2021-04-22T18:45:23.549081",
          "exception": false,
          "start_time": "2021-04-22T18:45:21.399178",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_IV(dataframe, coluna_feature, coluna_target, cat_goods = None, buckets=20):\n",
        "    '''\n",
        "    Function to calculate the IV.\n",
        "         Parameters\n",
        "         dataframe: DataFrame with the input and target variables.\n",
        "         column_feature (str): Name of the variable that contains the independent variable.\n",
        "         column_target (str): Name of the variable that contains the dependent variable or target.\n",
        "         cat_goods (str): Level of the target variable that should be considered \"GOOD\", if it is categorical.\n",
        "         buckets (int): Number of partitions to be created in numeric variables.\n",
        "    \n",
        "    Returns\n",
        "    stats (list):\n",
        "    List with:\n",
        "        [1] IV\n",
        "        [0] dataframe pandas with statistics table\n",
        "    '''\n",
        "    \n",
        "    # Initial definitions\n",
        "    df = dataframe.loc[:,(coluna_feature, coluna_target)]\n",
        "    tpVar = 'categorical'    \n",
        "    \n",
        "    #If the variable is numeric (float or int), it creates a category for discretization\n",
        "    if df[coluna_feature].dtype=='float64' or df[coluna_feature].dtype=='int64' or df[coluna_feature].dtype=='int32' or df[coluna_feature].dtype=='float32':\n",
        "        tpVar='numeric'\n",
        "        coluna_feature_bucket = coluna_feature + \"_bucket\"\n",
        "        #create buckets using qcut\n",
        "        df[coluna_feature_bucket] = pd.qcut(df[coluna_feature], buckets, labels=False, duplicates='drop')\n",
        "        analyse_df = df.groupby(coluna_feature_bucket, dropna=False).agg({coluna_target: ['count', 'sum'], coluna_feature: ['min', 'max']})\n",
        "        analyse_df.columns = ['_'.join(tup).rstrip('_') for tup in analyse_df.columns.values]\n",
        "        analyse_df.rename(columns={(coluna_target+'_count'):'qty', (coluna_target+'_sum'):'qty_goods'}, inplace=True)\n",
        "        \n",
        "    #Categorical variables\n",
        "    if tpVar == 'categorical':\n",
        "        analyse_df = df.groupby(coluna_feature, dropna=False).agg({coluna_target: ['count', 'sum']})\n",
        "        analyse_df.columns = ['_'.join(tup).rstrip('_') for tup in analyse_df.columns.values]\n",
        "        analyse_df.rename(columns={(coluna_target+'_count'):'qty', (coluna_target+'_sum'):'qty_goods'}, inplace=True)\n",
        "        \n",
        "    #IV Calculation\n",
        "    analyse_df.loc[:, 'qty_bads'] = analyse_df.loc[:,'qty'] - analyse_df.loc[:,'qty_goods']\n",
        "    analyse_df.loc[:, 'tot_goods'] = analyse_df.loc[:,'qty_goods'].sum()\n",
        "    analyse_df.loc[:, 'tot_bads'] = analyse_df.loc[:,'qty_bads'].sum()\n",
        "    analyse_df.loc[:, 'perc_goods'] = analyse_df.loc[:,'qty_goods'] / analyse_df.loc[:,'tot_goods']\n",
        "    analyse_df.loc[:, 'perc_bads'] = analyse_df.loc[:,'qty_bads'] / analyse_df.loc[:,'tot_bads']\n",
        "    analyse_df.loc[:, 'good_rate'] = analyse_df.loc[:,'qty_goods'] / analyse_df.loc[:,'qty']\n",
        "    analyse_df.loc[:, 'odds'] = analyse_df.loc[:,'perc_goods'] / analyse_df.loc[:,'perc_bads']\n",
        "    try:\n",
        "        analyse_df.loc[:, 'ln_odds'] = np.log2(analyse_df['odds'])\n",
        "    except:\n",
        "        analyse_df.loc[:, 'ln_odds'] = 0\n",
        "    analyse_df.loc[:, 'iv_cat'] = (analyse_df.loc[:,'perc_goods'] / analyse_df.loc[:,'perc_bads']) * analyse_df.loc[:, 'ln_odds']\n",
        "    \n",
        "    if tpVar == 'numeric':\n",
        "        analyse_df.reset_index(inplace=True)\n",
        "        tabela_pdf = analyse_df.loc[:, (coluna_feature_bucket, coluna_feature+\"_min\", coluna_feature+\"_max\", 'qty', 'good_rate', 'odds', 'iv_cat')]\n",
        "    else:\n",
        "        analyse_df.reset_index(inplace=True)\n",
        "        tabela_pdf = analyse_df.loc[:, (coluna_feature, 'qty', 'good_rate', 'odds', 'iv_cat')]\n",
        "        \n",
        "    df_iv = tabela_pdf.query('iv_cat != inf')['iv_cat'].sum()\n",
        "    resultado = [df_iv, tabela_pdf]\n",
        "    return resultado\n",
        "\n",
        "def colunas_dataframe(dataframe):\n",
        "    lista_colunas = []\n",
        "    lista_colunas = [i for i in dataframe.columns if i in selected_features]\n",
        "    return lista_colunas\n",
        "\n",
        "def table_iv(dataframe):\n",
        "    lista_colunas = colunas_dataframe(dataframe)\n",
        "    dict_resultados = {}\n",
        "    for col in lista_colunas:\n",
        "#         print(\"{0:.0%}\".format((lista_colunas.index(col)+1) / (len(lista_colunas)+1)) + \":\" + col)              \n",
        "        dict_resultados[col] = calculate_IV(dataframe=dataframe, coluna_feature=col, coluna_target=VarTarget, buckets=10)\n",
        "    return dict_resultados"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469673458
        },
        "papermill": {
          "duration": 2.111529,
          "end_time": "2021-04-22T18:45:27.784524",
          "exception": false,
          "start_time": "2021-04-22T18:45:25.672995",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = dt.datetime.now()\n",
        "\n",
        "result_data = table_iv(dataprep_df)\n",
        "result_formated = pd.DataFrame.from_dict(data=result_data, orient='index').reset_index().rename(columns={'index': 'Variable', 0: 'IV'}).drop(columns=1)\n",
        "result_formated_graph = result_formated.sort_values(by=['IV'], ascending=False)\n",
        "                                                                                                                 \n",
        "#Execution time\n",
        "stop = dt.datetime.now()\n",
        "execution_time = stop-start\n",
        "print(\"\\n\"+\"Execution time: \" + str (execution_time)+\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469673862
        },
        "papermill": {
          "duration": 2.275156,
          "end_time": "2021-04-22T18:45:31.908227",
          "exception": false,
          "start_time": "2021-04-22T18:45:29.633071",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "sns.barplot(y=\"Variable\", x=\"IV\", data=result_formated_graph.head(40), palette=\"Blues_r\").set_title(\"Information Value (IV)\")\n",
        "plt.axvline (x=0.02, linestyle=\"--\", color='r')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469674282
        },
        "papermill": {
          "duration": 2.68377,
          "end_time": "2021-04-22T18:45:36.442338",
          "exception": false,
          "start_time": "2021-04-22T18:45:33.758568",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Charts with the good rate (% of target = 1) by categories or by value range for numeric variables (ranges created by decile)"
      ],
      "metadata": {
        "papermill": {
          "duration": 1.845834,
          "end_time": "2021-04-22T18:45:40.202111",
          "exception": false,
          "start_time": "2021-04-22T18:45:38.356277",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in selected_features:\n",
        "    df_plot_tmp = result_data[i][1]\n",
        "    df_plot_tmp['Distribution'] = df_plot_tmp.qty / df_plot_tmp.qty.sum()\n",
        "    if i in CAT:\n",
        "        print('--------------------------------------- ' + str(i))\n",
        "        df_plot_tmp = df_plot_tmp.sort_values(by='good_rate', ascending=False)\n",
        "        df_plot_t1 = df_plot_tmp.loc[:, (i,'Distribution')]\n",
        "        df_plot_t1 = df_plot_t1.set_index(i)\n",
        "        df_plot_t2 = df_plot_tmp.loc[:, (i, 'good_rate')]\n",
        "        df_plot_t2 = df_plot_t2.set_index(i)\n",
        "        df_plot_t1.Distribution.plot(ylim=[0,1], kind='bar', rot=90, figsize=(15,5), linewidth=2, fontsize=12, grid=True, legend=1, title=i)\n",
        "        ax = df_plot_t2.good_rate.plot(secondary_y=True, kind=\"line\", rot=90, figsize=(15,5), linewidth=2, fontsize=12\\\n",
        "                                       , marker=\"D\", ms=8, grid=True, color='r', legend=1)\n",
        "        for p in range(len(df_plot_t2)):\n",
        "            ax.annotate(str('{0:.1%}'.format(int(df_plot_t2.reset_index().iloc[p,1]*1000)/1000))\\\n",
        "                            ,(df_plot_t2.reset_index().index.values[p]\\\n",
        "                              ,df_plot_t2.reset_index().iloc[p,1]*1))\n",
        "        target_mean = sum(df_plot_tmp.qty * df_plot_tmp.good_rate) / sum(df_plot_tmp.qty)\n",
        "        ax.axhline(y=target_mean, color='r', linestyle='--')\n",
        "        plt.show()\n",
        "        #display(ax)\n",
        "    else:\n",
        "        sort_var = str(i)+\"_max\"\n",
        "        print('--------------------------------------- ' + str(i))\n",
        "        df_plot_tmp[sort_var] = df_plot_tmp[sort_var].astype(float)\n",
        "        df_plot_tmp = df_plot_tmp.sort_values(by=sort_var)\n",
        "        df_plot_tmp[i] = df_plot_tmp[sort_var].fillna(999999999.99).astype(float)\n",
        "        df_plot_tmp[i] = (df_plot_tmp[i]*100).astype(int)/100\n",
        "        df_plot_tmp[i] = df_plot_tmp[i].astype(str).replace(\"999999999.99\", \"missing\")\n",
        "        df_plot_t1 = df_plot_tmp.loc[:, (i, 'Distribution')]\n",
        "        df_plot_t1 = df_plot_t1.set_index(i)\n",
        "        df_plot_t2 = df_plot_tmp.loc[:, (i, 'good_rate')]\n",
        "        df_plot_t2 = df_plot_t2.set_index(i)\n",
        "        df_plot_t1.Distribution.plot(ylim=[0,1], kind='bar', rot=90, figsize=(15,5), linewidth=2, fontsize=12, grid=True, legend=1, title=(i + \": ranges by decile\"))\n",
        "        ax = df_plot_t2.good_rate.plot(secondary_y=True, kind=\"line\", rot=90, figsize=(15,5), linewidth=2, fontsize=12, marker=\"D\", ms=8, grid=True, color='r', legend=1)\n",
        "        for p in range(len(df_plot_t2)):\n",
        "            ax.annotate(str('{0:.1%}'.format(int(df_plot_t2.reset_index().iloc[p,1]*1000)/1000)), (df_plot_t2.reset_index().index.values[p], df_plot_t2.reset_index().iloc[p,1]*1))        \n",
        "        target_mean = sum(df_plot_tmp.qty * df_plot_tmp.good_rate) / sum(df_plot_tmp.qty)\n",
        "        ax.axhline(y=target_mean, color='r', linestyle='--')\n",
        "        plt.show()\n",
        "        #display(ax)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1669469675703
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Save final dataset with the selected features to CSV"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dataprep_df.loc[:, (selected_features+[VarTarget, VarId, VarDate, 'dataset'])].to_csv('./titanic/dataprep_df.csv', index=False, header=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "gather": {
          "logged": 1669469676922
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "instance_type": "ml.t3.medium",
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}